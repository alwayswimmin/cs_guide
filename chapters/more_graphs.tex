\chapter{More Graph Algorithms}

With the renewal of strongly connected components and network flow in the IOI syllabus, we  overview some more graph algorithms that are standard but also noticeably more difficult than other algorithms presented in earlier chapters.

\section{Strongly Connected Components}

This section covers Tarjan's algorithm detects strongly connected components in a directed graph. We begin with the DFS traversal of the graph, building a forest (collection of trees). In a DFS, we only traverse each vertex once; this means when we encounter an edge to a vertex we already visited, we move on without calling the DFS on that node. Once we obtain the forest, we can split it into subgraphs that represent our strongly connected components.

Let's work through how we can get the subgraphs representing the strongly connected components from our DFS. Here's the graph from the beginning of this section.

\begin{center}
\begin{tikzpicture}[very thick,level/.style={sibling distance=70mm/#1}]
\draw (0, 0) node [vertex] (n1) {5};
\draw (2, 0) node [vertex] (n2) {6};
\draw (4, 0) node [vertex] (n3) {7};
\draw (6, 0) node [vertex] (n4) {8};
\draw (0, 2) node [vertex] (m1) {1};
\draw (2, 2) node [vertex] (m2) {2};
\draw (4, 2) node [vertex] (m3) {3};
\draw (6, 2) node [vertex] (m4) {4};
\draw[->] (m1) -- (m2);
\draw[->] (m2) -- (n1);
\draw[->] (n1) -- (m1);
\draw[->] (n2) edge [bend left] (m2);
\draw[->] (m2) edge [bend left] (n2);
\draw[->] (n2) -- (n3);
\draw[->] (m2) -- (m3);
\draw[->] (m2) -- (n3);
\draw[->] (n3) -- (m3);
\draw[->] (n3) edge [bend left] (m4);
\draw[->] (m4) edge [bend left] (n3);
\draw[->] (n4) -- (m4);
\end{tikzpicture}
\end{center}

It doesn't matter from which node we begin our DFS or the order in which we choose children; in our example, we'll simply choose the node with the minimum label to traverse first. This will result in two trees in our forest, one rooted at 1 and the other rooted at 8.

\begin{center}
\begin{tikzpicture}[very thick,level/.style={sibling distance=70mm/#1}, edge from parent/.style={draw, ->}]
\node [vertex] (n1) {1}
child {
	node [vertex] (n2) {2}
	child {
		node [vertex] (n3) {3}
	}
	child {
		node [vertex] (n5) {5}
	}
	child {
		node [vertex] (n6) {6}
		child {
			node [vertex] (n7) {7}
			child {
				node [vertex] (n4) {4}
			}
		}
	}
};
\node [vertex] [right=5cm of n1] (n8) {8};
\end{tikzpicture}
\end{center}

Now this by itself is not very useful, as in order to find strongly connected components, we'll need the edges in the directed graph that aren't included in our tree. Here we add the other edges as dashed pointers.

\begin{center}
\begin{tikzpicture}[very thick,level/.style={sibling distance=70mm/#1}, edge from parent/.style={draw, ->}]
\node [vertex] (n1) {1}
child {
	node [vertex] (n2) {2}
	child {
		node [vertex] (n3) {3}
	}
	child {
		node [vertex] (n5) {5}
	}
	child {
		node [vertex] (n6) {6}
		child {
			node [vertex] (n7) {7}
			child {
				node [vertex] (n4) {4}
			}
		}
	}
};
\node [vertex] [right=5cm of n1] (n8) {8};
\draw[->, dashed] (n5) edge [bend left] (n1);
\draw[->, dashed] (n6) edge [bend right] (n2);
\draw[->, dashed] (n2) edge [bend right] (n7);
\draw[->, dashed] (n4) edge [bend right] (n7);
\draw[->, dashed] (n8) edge [bend left] (n4);
\draw[->, dashed] (n7) edge [bend left] (n3);
\end{tikzpicture}
\end{center}

Note that strongly connected components are represented by subtrees in the graph. We call the root of the subtree called the root of the strongly connected component.

One edge here is immediately useless. We already know that 2 can reach 7; 7 is in 2's subtree. The fact that there is an edge from 2 to 7 doesn't change anything. Then we have a crucial observation -- the only possible useful extra edges are those that go up to a previous node in the subtree, like the edge from 5 to 1, or those that go ``left'' to a previously-visited vertex, either to a previous branch in the tree, like from 7 to 3, or to a previous subtree entirely, like from 8 to 4.

If a node $v$ has an edge to a direct ancestor in the tree, that means we immediately have a cycle, and therefore the node, its ancestor, and every vertex along the way must be in the same strongly connected component.

Naturally, the ``left'' case is trickier. Suppose $v$ has a left edge to a vertex $u$. We somehow need a way to find out if $u$ has a path back to $v$. We know that $u$ cannot go down the tree to $v$ as $v$ is not in the subtree of $u$ by the way DFS constructed the tree. Therefore, we want to know whether $u$ has a path back up to some common ancestor with $v$. However, again by the way DFS traverses the graph, the entire subtree of $u$ has already been searched before the DFS reaches $v$. We want to exploit this fact with some kind of memoization.

If vertex $v$ was the $n$th vertex visited in the DFS, we'll mark $v$ with the label $order(v) = n$. We'll also keep track of the ``least'' vertex $link(v)=u$ that we know up to that point that $v$ can visit, or the vertex $u$ with the minimum $order(u)$ that $v$ can reach so far.

As we're using a DFS, we'll use a stack $S$ to keep track of nodes we've visited. In a normal DFS on a tree, once we finish exploring a vertex $v$, we pop off $v$ from the stack. This will not be the case for us. A node remains on the stack iff it has a path to some node earlier in the stack.

This means as we explore the descendents of a vertex $v$, we'll know if $v$ has a path back to a previous vertex. That is, if $link(v) < order(v)$, it stays on the stack. If $link(v) = order(v)$, we take it off the stack.

Now we describe Tarjan's algorithm. Here, $num$ represents a global variable that indicates how many vertices have been visited so far.

\begin{algorithm}[H]
\caption{Tarjan}
\begin{algorithmic}
\Function{StrongConnect}{vertex $u$}
	\State $num \gets num + 1$		\Comment increment $num$
	\State $order(u) \gets num$		\Comment set $order(u)$ to smallest unused number
	\State $link(u) \gets order(u)$	\Comment least $order(v)$ accessible is $u$ itself
	\State push $u$ on $S$
	\ForAll{neighbors $v$ of $u$}
		\If{$order(v)$ is undefined}	\Comment $v$ has not been visited
			\State \Call{StrongConnect}{$v$}
			\State $link(u) \gets \min(link(u), link(v))$
		\ElsIf{$v$ is on stack $S$}		\Comment $v$ is in current component
			\State $link(u) \gets \min(link(u), order(v))$
		\EndIf
	\EndFor
	\If{$link(u) = order(u)$}			\Comment $u$ is root of component, create SCC
		\State create new strongly connected component
		\Repeat
			\State $v \gets$ top of $S$
			\State add $v$ to strongly connected component
			\State pop top from $S$
		\Until{$u=v$}
	\EndIf
\EndFunction
\Function{Tarjan}{$G(V,E)$}
	\State $num \gets 0$
	\State initialize new empty stack $S$
	\ForAll{vertices $v \in V$}
		\If{$order(v)$ is undefined}	\Comment $v$ has not been visited
			\State \Call{StrongConnect}{$v$}
		\EndIf
	\EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

This algorithm runs in $O(V+E)$.

\section{Network Flow}

We are given a directed graph with weighted edges, a source node, and a sink node. A \textit{flow} is sent from the source to the sink. Each edge weight represents the maximum capacity of that edge. For every node besides the source and the sink node, total flow in is equal to total flow out. We can think of a flow network as a series of pipes through which water travels from an entrance to an exit in the network. The edge capacities represent pipe thickness. At any node, the total rate at which water enters the node must equal the total rate at which it exits the node, and along any path, the rate at which water flows is bottlenecked by the thinnest pipe.

More formally, for a graph $G(V,E)$, where $c(u,v)$ represents the capacity of the edge from $u$ to $v$, the flow $f(u,v)$ from a source $s$ to a sink $t$ satisfies

\begin{alignat*}{2}
f(u,v) &\le c(u,v)   \quad && \forall (u,v) \in E \\
f(u,v) &= -f(v,u)   \quad && \forall (u,v) \in E \\
\sum_{v \in V} f(u,v) &= 0   \quad && \forall u \in V \setminus \{s,t\} \\
\sum_{v \in V} f(s,v) &= \sum_{v \in V} f(v,t) = |f|, \quad &&
\end{alignat*}

where $|f|$ represents the total flow from the source to the sink.

A \textit{maximum flow} is one that maximizes the total flow $|f|$ from $s$ to $t$, or in our example, maximizes the rate at which water can flow through our network.

We'll also define the residual capacity $c_f(u,v) = c(u,v) - f(u,v)$. Note that $c_f(u,v) \ge 0$ by the conditions imposed on $f$. The residual capacity of an edge represents how much capacity is left after a certain amount of flow has already been sent. We therefore have the residual graph $G_f(V,E_f)$, where $E_f$ is the graph of residual edges, or all edges $(u,v) \in V^2$ satisfying $c_f(u,v) > 0$.

A natural approach to ``solving'' this problem would be to simply greedily add flow.

Find a path from the source to the sink in which all the edges have positive weight in the residual graph. Send flow along this path; that is, find the max flow across this path, which is the minimum weight of any edge on this particular path. Call this value $cap$. Then subtract $cap$ from the residual capacity of every edge in the path. We repeat, and this is guaranteed to terminate since on any given move, we remove an edge from our residual graph.

What is wrong with our greedy approach? Consider the following graph:

\begin{center}
\begin{tikzpicture}[very thick,level/.style={sibling distance=70mm/#1}]
\draw (0, 0) node [vertex] (n1) {1};
\draw (2, 1) node [vertex] (n2) {2};
\draw (2, -1) node  [vertex] (n3) {3};
\draw (4, 0) node [vertex] (n4) {4};
\draw[->] (n1) -- (n2) node[midway, above] {2};
\draw[->] (n2) -- (n3) node[midway, right] {2};
\draw[->] (n3) -- (n4) node[midway, below] {2};
\draw[->] (n2) -- (n4) node[midway, above] {1};
\draw[->] (n1) -- (n3) node[midway, below] {1};
\end{tikzpicture}
\end{center}

The max flow from vertex 1 to vertex 4 is 3, but greedy gives only 2. This is because the best possible single path from the source to the sink may not be included the best possible overall flow.

\subsection{Ford-Fulkerson}

We somehow need a way to fix the inclusion of any suboptimal paths in our greedy approach, or to ``send flow back'' in case we sent it through a suboptimal path. We do this by introducing the \textit{reverse edge} to our residual graph.

Find a path from the source to the sink in which all the edges have positive weight in the residual graph. Find the max flow across this path, which is the minimum weight of any edge on this particular path. Call this value $cap$. Then subtract $cap$ from the residual capacity of every edge along the path and \textit{increment the residual capacity of the reverse edge} (the edge connecting the same two vertices but running in the opposite direction) by $cap$. We call this operation on the path \textit{augmenting the path}. We simply choose an augmenting path until no such paths exist.

\begin{algorithm}[H]
\caption{Ford-Fulkerson}
\begin{algorithmic}
\Function{AugmentPath}{path $p=\{v_i\}_{i=1}^m$, where $(v_i,v_{i+1}) \in E_f$, $v_1=s$, $v_m=t$}
\State $cap \gets \min_{i=1}^{m-1}(c_f(v_i,v_{i+1}))$
\For{$i \equiv 1, m-1$}
	\State $f(v_i,v_{i+1}) \gets f(v_i,v_{i+1}) + cap$
	\State $c_f(v_i,v_{i+1}) \gets c_f(v_i,v_{i+1}) + cap$
	\State $f(v_{i+1},v_i) \gets f(v_{i+1},v_i) - cap$
	\State $c_f(v_{i+1},v_i) \gets c_f(v_{i+1},v_i) + cap$
	\Comment incrementing reverse edge
\EndFor
\EndFunction
\Function{MaxFlow}{$G(V,E)$, $s,t \in V$}
	\ForAll{$(u,v) \in V^2$}
		\State $f(u,v) \gets 0$
		\State $c_f(u,v) \gets c(u,v)$
	\EndFor
	\State $|f| \gets 0$
	\While{$\exists p=\{v_i\}_{i=1}^m$, where $(v_i,v_{i+1}) \in E_f$, $v_1=s$, $v_m=t$}
		\State $cap \gets \min_{i=1}^{m-1}(c_f(v_i,v_{i+1}))$
		\State $|f| \gets |f| + cap$
		\State \Call{AugmentPath}{$p$}
	\EndWhile
	\Return $|f|$
\EndFunction
\end{algorithmic}
\end{algorithm}

The difference between this algorithm and the greedy approach from earlier is that the paths we now allow may run along a reverse path, essentially undoing any suboptimal flow from earlier. These more general paths in our residual graph are called \textit{augmenting paths}.

This algorithm is guaranteed to terminate for graphs with integral weights. Its performance is bounded by $O(Ef)$, where $f$ is the maximum flow and $E$ is the number of edges, as finding a path from $s$ to $t$ takes $O(E)$ and increments the total flow $f$ by at least 1. The concept of removing edges can't be used to produce a stricter bound because while an edge in one direction may be removed from the residual graph, doing so creates an edge in the other direction.

In its crudest form, Ford-Fulkerson does not specify on which path to push flow if multiple paths exist. It simply states that as long as such a path exists, push flow onto it. In addition to being slow, Ford-Fulkerson, as it is stated, is not guaranteed to terminate for graphs with non-integral capacities. In fact, it might not even converge to the maximum flow for irrational capacities. However, these problems can be fixed by simply specifying how the algorithm chooses the next path on which to push flow. Nonetheless, the Ford-Fulkerson algorithm is formulated beautifully mathematically and such is useful from a math perspective, as we will see with the Max-Flow Min-Cut Theorem.

\subsection{Max-Flow Min-Cut Theorem}

On a graph $G(V,E)$, an \textit{s-t cut} $C=(S,T)$ splits the partitions $V$ into $S$ and $T$ satisfying $s \in S$ and $t \in T$. The \textit{cut-set} of $C$ is the set of edges $\{(u,v) \in E : u \in S, v \in T\}$. The \textit{capacity} of an s-t cut is given by

\[c(S,T) = \sum_{(u,v) \in S \times T}c(u,v).\]

A \textit{minimum cut} is an s-t cut that minimizes $c(S,T)$.

A cut represents a set of edges that, once removed, separates $s$ from $t$. A minimum cut is therefore a set of edges that does this but minimizes the total capacity of the edges necessary to disconnect $s$ from $t$.

The max-flow min-cut theorem states that the maximum value of any s-t flow is equal to the minimum capacity of any s-t cut.

First, the capacity of any cut must be at least the total flow. This is true by contradiction. Any path from $s$ to $t$ has an edge in the cut-set, so therefore any flow from $s$ to $t$ is upper bounded by the capacity of the cut. Therefore, we need only construct one flow and one cut such that the capacity of the cut is equal to the flow.

We consider the residual graph $G_f$ produced at the completion of the Ford-Fulkerson augmenting path algorithm.\footnote{If you're concerned that the Ford-Fulkerson algorithm will never terminate, there always exists a sequence of paths chosen such that it will. Edmonds-Karp is one example that always terminates.} Let the set $S$ be all nodes reachable from $s$ and $T$ be $V \setminus S$. We wish to show that $C=(S,T)$ is a cut satisfying $|f|=c(S,T)=\sum_{(u,v) \in S \times T} c(u,v)$. This is true when the following is satisfied:

\begin{enumerate}

\item
All edges $(u,v) \in S \times T$ are fully saturated by the flow. That is, $c_f(u,v) = 0$.

\item
All reverse edges $(v, u) \in T \times S$ have zero flow. That is, $f(v,u) = 0$, or $c_f(v,u) = c(v,u)$.

\end{enumerate}

The first condition is true by the way we constructed $S$ and $T$, as if there existed a $(u,v)$ where $c_f(u,v) > 0$, then $v$ is accessible to $s$ and ought to have been in $S$.

The second condition is true by the way the Ford-Fulkerson algorithm constructed reverse edges. If net flow was sent from $v$ to $u$, then a reverse edge was constructed from $u$ to $v$, so again, $v$ is accessible to $s$, which is a contradiction.

Therefore, we have the flow
\[|f|=\sum_{(u,v) \in S \times T} c(u,v) - \sum_{(v,u) \in T \times S} 0 = c(S,T),\]
so we constructed a flow and a cut such that the flow $|f|$ is equal to the cut capacity $c(S,T)$, and we are done.

\subsection{Refinements of Ford-Fulkerson}

As stated earlier, Ford-Fulkerson is limited by not specifying on which path to push flow. There are many algorithms that resolve this issue in different ways.

\subsubsection{Edmonds-Karp}

Edmonds-Karp fixes the problem by simply choosing the augmenting path of shortest unweighted length. This can be done easily using a BFS.

\begin{algorithm}[H]
\caption{Edmonds-Karp}
\begin{algorithmic}
\Function{ChoosePath}{$G_f(V,E_f)$, $s,t \in V$}
	\Comment{BFS}
	\State $visited(v)$ denotes $v$ has been added to queue
	\State $prev(v)$ denotes vertex preceding $v$ in BFS
	\State push $s$ on queue $Q$
	\State $visited(s) \gets 1$
	\While{$Q$ is not empty}
		\State $u \gets $ top of $Q$
		\ForAll{neighbors $v$ of $u$ in $G_f$ where $visited(v)=0$}
			\State push $v$ on $Q$
			\State $visited(v) \gets 1$
			\State $prev(v) \gets u$
		\EndFor
	\EndWhile
	\State pointer $curr \gets t$
	\While{$curr \not= s$}
		\State add $curr$ to beginning of path $p$
		\State $curr \gets prev(curr)$
	\EndWhile
	\State add $s$ to beginning of $p$
	\State \Return $p$
\EndFunction
\Function{MaxFlow}{$G(V,E)$, $s,t \in V$}
	\ForAll{$(u,v) \in V^2$}
		\State $f(u,v) \gets 0$
		\State $c_f(u,v) \gets c(u,v)$
	\EndFor
	\State $|f| \gets 0$
	\While{$t$ can be reached from $s$}
		\State $p \gets \Call{ChoosePath}{G_f,s,t}$
		\State $cap \gets \min_{i=1}^{m-1}(c_f(v_i,v_{i+1}))$
		\State $|f| \gets |f| + cap$
		\State \Call{AugmentPath}{$p$}
	\EndWhile
	\Return $|f|$
\EndFunction
\end{algorithmic}
\end{algorithm}

The BFS is clearly $O(E)$. To complete our analysis, we must somehow bound the number of times we need to perform the BFS. To do this, we'll look at what pushing flow on a path does to our residual graph; in particular, how it affects our BFS traversal tree. Note that each vertex is on some level $i$ in the BFS tree, characterized by the distance from the source $s$. For example, $L_0 = \{s\}$, $L_1$ contains all the neighbors of $s$, $L_2$ contains neighbors of neighbors not in $L_0$ or $L_1$, and so on.

We first claim that the level of any vertex in the graph is nondecreasing following an augment on a path $p$. If the augment saturates an edge, it may remove it from $G_f$, which cannot decrease the distance of any vertex from $s$. If the augment creates an edge $e=(u,v)$, that means we sent flow from $v$ to $u$ on the path $p$. Therefore, if $v$ was originally level $i$, $u$ must have been level $i+1$. The level of $u$ does not change by adding $(u,v)$, and the level of $v$ can either be $i$ or $i+2$, depending on whether edge $(v,u)$ was deleted in the process. Either way, the level of all vertices is nondecreasing.

Now consider the bottleneck edge $e=(u,v)$ of an augmenting path $p$, where the level of $u$ is $i$ and the level of $v$ is $i+1$. The push operation deletes the edge $e$, but the level of $v$ must stay at least $i+1$. Now for the edge $e$ to reappear in the graph $G_f$, flow must have been sent on the reverse edge $e'=(v,u)$ on some augmenting path $p'$. But on path $p'$, $u$ comes after $v$, which must be at least level $i+1$. Therefore, $u$ must be at least level $i$. But since the maximum level of a node that is connected to $s$ is $V-1$, an edge $e$ can only be chosen as the bottleneck edge $\frac{V}{2}$ times, or $O(V)$.

There are $E$ edges, each of which can be the bottleneck edge for $O(V)$ different augmenting paths, each of which takes $O(E)$ to process. Therefore, the Edmonds-Karp algorithm runs in $O(VE^2)$.

\subsubsection{Dinic}

Dinic's algorithm is another refinement of Ford-Fulkerson.

\subsection{Push-Relabel}

Unfortunately, even the much-improved bounds of the $O(VE^2)$ Edmonds-Karp are admittedly bad. While the push-relabel method for solving the max flow problem does not have the fastest theoretical bounds, two of its implementations have complexities $O(V^3)$ and $O(V^2\sqrt{E})$ and are among the fastest in practice.

\subsubsection{Generic Push-Relabel}

Ford-Fulkerson and its variants all deal with global augmentations of paths from $s$ to $t$. Push-relabel takes a different perspective, introducing the concept of a \textit{preflow} and a \textit{height} to make local optimizations that ultimately result in the maximum flow.

A preflow maintains the same properties as a flow but modifies the conservation of flow condition. Instead of total flow in equalling total flow out, flow in must be at least, and therefore can exceed, flow out. We denote the difference between flow in and flow out as the \textit{excess} $e(v)$.

\begin{alignat*}{2}
f(u,v) &\le c(u,v)   \quad && \forall (u,v) \in E \\
f(u,v) &= -f(v,u)   \quad && \forall (u,v) \in E \\
e(v) = \sum_{u \in V} f(u,v) &\ge 0   \quad && \forall v \in V \setminus \{s\} \\
e(s) &= \infty. \quad &&
\end{alignat*}

The definitions of the residual capacity $c_f(u,v)$, edge set $E_f$, and graph $G_f$ are the same as they were defined before, except with a preflow $f$ instead of a normal flow.

We call a vertex $v \in V \setminus \{s, t\}$ \textit{active} if $e(v) > 0$. Therefore, a vertex besides the source or sink is active if more flows into the vertex than flows out. $s$ and $t$ are \textit{never} active. A preflow with no active vertices is simply a flow, at which point the excess of the sink $e(t)$ represents the value $|f|$ of the flow.

We can \textit{push} flow from a node $u$ to a node $v$ by moving as much of the excess $e(u)$ to $v$ as the capacity of the edge $c_f(u,v)$ will allow.

\noindent \begin{minipage}{\textwidth}
\begin{algorithmic}
\Function{Push}{edge $(u,v)$}
	\State $\delta \gets \min(e(u), c_f(u,v))$
	\Comment $c_f(u,v) = c(u,v) - f(u,v)$
	\State $f(u,v) \gets f(u,v) + \delta$
	\State $f(v,u) \gets f(v,y) - \delta$
	\State $e(u) \gets e(u) - \delta$
	\State $e(v) \gets e(v) + \delta$
\EndFunction
\end{algorithmic}
\end{minipage}

The idea of the push-relabel algorithm is to first push as much preflow as possible through local optimizations in the direction the sink. When a node can no longer push flow to the sink, it pushes the excess back towards the source to turn the preflow into a flow.

However, the difficulty here lies in establishing this sense of ``direction'' from the source to the sink. Remember that we simply push preflow along a single edge in the graph at a time, not along a whole path. Moving flow from the source to the sink along a path that goes from the source to the sink is easy; moving flow from the source to the sink through local pushes without the knowledge of the graph structure as a whole is indeed a much harder problem.

To resolve this issue, we introduce a \textit{label} to each of the nodes. The label $h(u)$ represents the ``height'' of $u$. In real life, water flows from higher to lower ground. We want $s$ to represent that high ground and $t$ to represent the low ground. As we push preflow from $s$ to $t$, vertices along the way represent height values between those of $s$ and $t$. However, eventually we have to push preflow back to handle both excesses in flow and suboptimal previous pushes, \`{a} la Ford-Fulkerson, but this contradicts the concept of height as we can't flow both downhill and uphill. Therefore, we'll need to be able to \textit{relabel} a node, changing the height $h(u)$ to something that allows preflow to flow back towards $s$. We will relabel $h$ in a systematic way that allows us to direct the preflow through the graph.

For this labeling to be useful for us, we'll need to impose some more constraints that must be satisfied no matter how we change the graph $G_f$ or the height function $h$.

\begin{align*}
h(u) &\le h(v) + 1 \forall (u,v) \in E_f \\
h(s) &= |V| \\
h(t) &= 0.
\end{align*}

What does this mean? For our algorithm, we can push preflow along the edge from $u$ to $v$ only if $c_f(u,v) > 0$ and $h(u) > h(v)$, so $h(u) = h(v) + 1$. We call such an edge $(u,v) \in E_f$ \textit{admissible}. Furthermore, for all vertices $v$ that can reach $t$ in $E_f$, $h(v)$ represents the lower bound for the length of any unweighted path from $v$ to $t$ in $G_f$, and for all vertices that cannot reach $t$, then $h(v)-|V|$ is a lower bound for the unweighted distance from $s$ to $v$.

$t$ will always represent the lowest node, so $h(t)=0$ is a natural constraint. We'll first set the preflow values of all vertices $v$ that can be immediately reached from $s$ to $c(s,v)$, saturating all the out-edges of $s$. For any vertex $v$ from which $t$ can be reached, $h(v)$ represents the lower bound of the unweighted distance to $t$ from $v$ in the residual graph.

We want $h(s)$ to be a number large enough that will indicate that $s$ has been disconnected to $t$, as we have already sent as much preflow possible from $s$ in the direction of $t$ by saturating all outgoing edges. Therefore, setting $h(s)=|V|$ is also natural. Since $h(s)$ represents the lower bound of the distance from $s$ to $t$ in $G_f$, and there are no paths from $s$ to $t$ in the residual graph, $|V|$ is a natural choice, since the longest possible path is $|V|-1$.

Furthermore, we don't want any preflow sent back to $s$ from a vertex $v$ unless it is impossible to send any more preflow from $v$ to $t$. If preflow is pushed from $v$ to $s$, then $h(v) = |V| + 1$. If there existed a path $v$ to $t$ such that every edge is admissible, the path must have $|V| + 2$ vertices. This is true because for any two consecutive vertices $v_i,v_{i+1}$ in the path, $h(v_i) = h(v_{i+1}) + 1$, but no path can have $|V|+2$ distinct vertices.

This leads to the fact that the only nodes that can possibly continue to contribute to the final flow are active vertices $v$ for which $h(v) < |V|$. A node with height at least $|V|$ does not have a valid path to $t$, and a node that is not active doesn't have any excess flow to push.

Now that I've explained the general idea behind the labeling constraints, it's time to actually describe what our relabeling process is. At first, the labels of all vertices besides the source start at 0. We only relabel a node $v$ if it is active (therefore, it has excess flow it needs to push; $e(u) > 0$) but has no admissible out-edges in $G_f$ (so it has no adjacent vertex on which it can push that excess flow). If a node has no admissible out-edges in $G_f$, every neighbor of $u$ has a height label at least equal to $h(u)$. When we relabel a node, we always then \textit{increase} the value of $h(u)$ to the least value where it can push flow onto another node.

\noindent \begin{minipage}{\textwidth}
\begin{algorithmic}
\Function{Relabel}{vertex $u$}
		\State $h(u) \gets \min_{v | (u,v) \in E_f}(h(v)) + 1$
		\Comment $(u,v) \in E_f \iff c_f(u,v) = c(u,v) - f(u,v) > 0$
\EndFunction
\end{algorithmic}
\end{minipage}

Since we take the minimum height of all neighbors in the graph, we first try adjusting the height of $u$ so that we can push flow from $u$ to its neighbors that can possibly still reach $t$; that is, neighbors $v$ satisfying $h(v) < |V|$. Once we try all these neighbors, we then increase the height of $u$ to begin to push flow back towards $s$. We can always find such an edge, as any preflow pushed onto $u$ must have also incremented the reverse edge from $u$ back towards $s$.

Note that neither pushing on a admissible edge nor relabeling a vertex with no admissible out-edges changes the fact that $h$ remains a valid labeling function.

The generic push-relabel algorithm simply pushes and relabels vertices until there are no active vertices and the preflow becomes a flow. This algorithm works because throughout the process, $h$ remained a valid height function, and at the end, the preflow was converted into a flow. Since $h(s) = |V|$ and $h(t) = 0$, there is no augmenting path from $s$ to $t$, so our flow is maximal.

\begin{algorithm}[H]
\caption{Push-Relabel (Generic)}
\begin{algorithmic}
\Function{Push}{edge $(u,v)$}
	\If{$e(u) > 0$ and $h(u) = h(v) + 1$}
		\Comment push condition
		\State $\delta \gets \min(e(u), c_f(u,v))$
		\Comment $c_f(u,v) = c(u,v) - f(u,v)$
		\State $f(u,v) \gets f(u,v) + \delta$
		\State $f(v,u) \gets f(v,y) - \delta$
		\State $e(u) \gets e(u) - \delta$
		\State $e(v) \gets e(v) + \delta$
	\EndIf
\EndFunction
\Function{Relabel}{vertex $u$}
	\If{$u \not= s,t$ and $e(u)>0$ and $h(u) \le h(v) \forall v | (u,v) \in E_f$}
		\Comment relabel condition
		\State $h(u) \gets \min_{v | (u,v) \in E_f}(h(v)) + 1$
		\Comment $(u,v) \in E_f \iff c_f(u,v) = c(u,v) - f(u,v) > 0$
	\EndIf
\EndFunction
\Function{MaxFlow}{$G(V,E)$, $s,t \in V$}
	\ForAll{$v \in V \setminus \{s\}$}
		\Comment initialize excess
		\State $e(v) \gets 0$
	\EndFor
	\State $e(s) \gets \infty$
	\ForAll{$(u,v) \in V^2$}
		\Comment initialize preflow
		\State $f(u,v) \gets 0$
	\EndFor
	\ForAll{neighbors $v \not= s$ of $s$}
		\Comment saturate edges to all neighbors of $s$
		\State $f(s,v) \gets c(s,v)$
		\State $f(v,s) \gets -c(s,v)$
		\State $e(v) \gets c(s,v)$
	\EndFor
	\ForAll{$v \in V \setminus \{s\}$}
		\Comment preflow now has valid height function; initialize height
		\State $h(v) \gets 0$
	\EndFor
	\State $h(s) \gets |V|$
	\While{we can still \Call{Push}{} or \Call{Relabel}{}}
		\State \Call{Push}{} or \Call{Relabel}{}
	\EndWhile
	\State \Return $e(t)$
	\Comment $e(t)=|f|$
\EndFunction
\end{algorithmic}
\end{algorithm}

We can argue that this algorithm runs in $O(V^2E)$, which is already an improvement from Edmonds-Karp. However, just as Ford-Fulkerson could be sped up by specifying which augmenting paths to choose, we can do the same with the push-relabel algorithm, speeding it up by specifying a systematic method to choose an edge to push or a vertex to relabel.

\subsubsection{Discharge}

We first describe an auxiliary operation. For each vertex $u$, we'll need a way to visit in- and out-neighbors of $u$ in a static cyclic order. This is easy with just a pointer; for vertex $u$, we'll call that pointer $curr(u)$. When the pointer passes through every element in the list of neighbors, we'll just reset it back to the first element.

\noindent \begin{minipage}{\textwidth}
\begin{algorithmic}
\Function{Discharge}{vertex $u$}
	\While{$e(u)>0$}
		\Comment{perform an operation as long as $u$ is active}
		\If{$curr(u)$ is at end of list of neighbors}
			\State \Call{Relabel}{$u$}
			\State reset $curr(u)$
		\Else
			\If{$(u,curr(u))$ is an admissible edge}
				\State \Call{Push}{$(u,curr(u))$}
			\Else
				\State move $curr(u)$ to next neighbor of $u$
			\EndIf
		\EndIf
	\EndWhile
\EndFunction
\end{algorithmic}
\end{minipage}

\subsubsection{FIFO Selection}

FIFO selection simply maintains a list of active vertices in a FIFO queue. We pop off the first vertex in the queue and discharge it, adding any newly-activated vertices to the end of the queue. This runs in $O(V^3)$.

\subsubsection{Highest Label Selection}

Highest label selection discharges the active vertex with the greatest height. This runs in $O(V^2\sqrt{E})$.

\subsubsection{Improvements with Heuristics}

Heuristics are meant to help relabel vertices in a smarter way. Bad relabelings are the slowest part of the algorithm, and improving the process can speed up max flow.

The \textit{gap heuristic} takes advantage of ``gaps'' in the height function. Since a path of admissible edges consists of vertices whose heights decrease by exactly 1, the presence of a gap in height precludes the possibility of such a path. If there exists a value $h'$ such that no vertex $v$ exists such that $h(v)=h'$, then for every vertex $v$ satisfying $h' < h(v) < |V|$, $v$ has been disconnected from $t$, so we can immediately relabel $h(v)=|V| + 1$.

The \textit{global relabeling heuristic} performs a backwards BFS from $t$ every now and then to compute the heights of the vertices in the graph exactly.

Some dude on Codeforces\footnote{\url{http://codeforces.com/blog/entry/14378}} didn't have much luck improving performance with the global relabeling heuristic. I'd suggest sticking to the gap heuristic only.

\subsection{Other Problems with Flow Solutions}

\subsubsection{Edge-Disjoint Paths}

\subsubsection{Bipartite Matching}

The bipartite matching problem is perhaps the most well-known problem solvable by flows.






